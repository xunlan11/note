\contentsline {section}{\numberline {1}{导论}}{7}{section.1}%
\contentsline {paragraph}{{特征}}{7}{paragraph*.1}%
\contentsline {paragraph}{{其他优化方法}}{7}{paragraph*.2}%
\contentsline {paragraph}{{分类}}{7}{paragraph*.3}%
\contentsline {paragraph}{{发展}}{8}{paragraph*.4}%
\contentsline {section}{\numberline {2}{马尔可夫决策过程与贝尔曼方程}}{8}{section.2}%
\contentsline {subsection}{\numberline {2.1}{马尔可夫决策过程（Markov decision process，MDP）}}{8}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}{要素}}{8}{subsubsection.2.1.1}%
\contentsline {subsubsection}{\numberline {2.1.2}{状态、动作与收益}}{9}{subsubsection.2.1.2}%
\contentsline {paragraph}{{序贯交互轨迹（trajectory）$ \tau = S_0, A_0, R_1, S_1, A_1, R_2, \dots $}}{9}{paragraph*.6}%
\contentsline {paragraph}{{马尔可夫性}}{9}{paragraph*.7}%
\contentsline {paragraph}{{状态转移}}{9}{paragraph*.8}%
\contentsline {subsubsection}{\numberline {2.1.3}{策略}}{10}{subsubsection.2.1.3}%
\contentsline {paragraph}{{贪婪策略}}{10}{paragraph*.10}%
\contentsline {paragraph}{{探索-利用平衡策略}}{10}{paragraph*.11}%
\contentsline {paragraph}{{增量式更新}}{11}{paragraph*.12}%
\contentsline {subsubsection}{\numberline {2.1.4}{回报与折扣}}{11}{subsubsection.2.1.4}%
\contentsline {subsubsection}{\numberline {2.1.5}{值函数}}{11}{subsubsection.2.1.5}%
\contentsline {paragraph}{{值函数}}{12}{paragraph*.13}%
\contentsline {paragraph}{{行为值函数}}{12}{paragraph*.14}%
\contentsline {paragraph}{{回溯算法}}{12}{paragraph*.15}%
\contentsline {paragraph}{{最优值函数}}{12}{paragraph*.17}%
\contentsline {subsubsection}{\numberline {2.1.6}{构建要点}}{13}{subsubsection.2.1.6}%
\contentsline {subsection}{\numberline {2.2}{贝尔曼方程}}{13}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}{贝尔曼方程}}{13}{subsubsection.2.2.1}%
\contentsline {subsubsection}{\numberline {2.2.2}{贝尔曼最优方程}}{13}{subsubsection.2.2.2}%
\contentsline {paragraph}{{形式}}{13}{paragraph*.18}%
\contentsline {paragraph}{{描述方式}}{14}{paragraph*.20}%
\contentsline {paragraph}{{求解}}{14}{paragraph*.21}%
\contentsline {paragraph}{{贪婪最优策略}}{14}{paragraph*.22}%
\contentsline {section}{\numberline {3}{动态规划（Dynamic Programming，DP）：期望更新}}{15}{section.3}%
\contentsline {subsection}{\numberline {3.1}{策略迭代}}{15}{subsection.3.1}%
\contentsline {paragraph}{{策略评估（PE）}}{15}{paragraph*.24}%
\contentsline {paragraph}{{策略改进（PI）}}{15}{paragraph*.25}%
\contentsline {subsection}{\numberline {3.2}{值迭代}}{16}{subsection.3.2}%
\contentsline {paragraph}{{策略更新（PU）}}{16}{paragraph*.26}%
\contentsline {paragraph}{{价值更新（VU）}}{16}{paragraph*.27}%
\contentsline {subsection}{\numberline {3.3}{对比}}{17}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}{其他内容}}{17}{subsection.3.4}%
\contentsline {paragraph}{{异步动态规划}}{17}{paragraph*.28}%
\contentsline {paragraph}{{广义策略迭代（GPI）}}{17}{paragraph*.29}%
\contentsline {paragraph}{{动态规划的效率}}{17}{paragraph*.30}%
\contentsline {section}{\numberline {4}{蒙特卡洛（Monte Carlo，MC）：采样更新}}{18}{section.4}%
\contentsline {subsection}{\numberline {4.1}{概念}}{18}{subsection.4.1}%
\contentsline {paragraph}{{核心需求}}{18}{paragraph*.31}%
\contentsline {paragraph}{{行为值函数估计}}{18}{paragraph*.32}%
\contentsline {paragraph}{{幕长}}{18}{paragraph*.34}%
\contentsline {paragraph}{{优势}}{18}{paragraph*.35}%
\contentsline {subsection}{\numberline {4.2}{on-policy（同轨）}}{18}{subsection.4.2}%
\contentsline {paragraph}{{试探性出发（ES）}}{19}{paragraph*.36}%
\contentsline {subsection}{\numberline {4.3}{off-policy（离轨）}}{19}{subsection.4.3}%
\contentsline {paragraph}{{重要度采样（importance sampling）}}{19}{paragraph*.37}%
\contentsline {paragraph}{{增量式更新}}{20}{paragraph*.38}%
\contentsline {subsection}{\numberline {4.4}{对比}}{20}{subsection.4.4}%
\contentsline {section}{\numberline {5}{时序差分（Temporal Difference，TD）：采样更新}}{21}{section.5}%
\contentsline {subsection}{\numberline {5.1}{TD($ 0 $)}}{21}{subsection.5.1}%
\contentsline {paragraph}{{优势}}{21}{paragraph*.40}%
\contentsline {paragraph}{{随机游走}}{22}{paragraph*.41}%
\contentsline {paragraph}{{批量更新}}{22}{paragraph*.42}%
\contentsline {subsection}{\numberline {5.2}{Sarsa（on-policy-TD）}}{22}{subsection.5.2}%
\contentsline {paragraph}{{期望Sarsa}}{23}{paragraph*.44}%
\contentsline {subsection}{\numberline {5.3}{Q-learning（off-policy-TD）}}{23}{subsection.5.3}%
\contentsline {paragraph}{{双Q-learning}}{24}{paragraph*.47}%
\contentsline {subsection}{\numberline {5.4}{对比}}{25}{subsection.5.4}%
\contentsline {section}{\numberline {6}{n步自举法}}{25}{section.6}%
\contentsline {subsection}{\numberline {6.1}{n-TD}}{25}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}{n-Sarsa}}{26}{subsection.6.2}%
\contentsline {subsection}{\numberline {6.3}{n-树回溯}}{28}{subsection.6.3}%
\contentsline {paragraph}{{带控制变量的每次决策模型}}{28}{paragraph*.50}%
\contentsline {paragraph}{{n-树回溯}}{29}{paragraph*.51}%
\contentsline {subsection}{\numberline {6.4}{n-Q($ \sigma $)}}{30}{subsection.6.4}%
\contentsline {section}{\numberline {7}{表格型方法总结对比}}{32}{section.7}%
\contentsline {paragraph}{{表格型方法介绍}}{32}{paragraph*.54}%
\contentsline {paragraph}{{三个维度}}{32}{paragraph*.55}%
\contentsline {paragraph}{{更新}}{32}{paragraph*.57}%
\contentsline {paragraph}{{表达式对比}}{33}{paragraph*.59}%
\contentsline {section}{\numberline {8}{值函数近似}}{34}{section.8}%
\contentsline {subsection}{\numberline {8.1}{函数近似}}{34}{subsection.8.1}%
\contentsline {paragraph}{{目标函数}}{34}{paragraph*.62}%
\contentsline {paragraph}{{状态分布}}{34}{paragraph*.63}%
\contentsline {paragraph}{{优势}}{34}{paragraph*.64}%
\contentsline {subsection}{\numberline {8.2}{随机梯度下降（SGD）}}{35}{subsection.8.2}%
\contentsline {paragraph}{{负梯度方向降速最快}}{35}{paragraph*.65}%
\contentsline {paragraph}{{步长$ \alpha $}}{35}{paragraph*.66}%
\contentsline {paragraph}{{近似方法}}{35}{paragraph*.67}%
\contentsline {paragraph}{{半梯度方法}}{35}{paragraph*.68}%
\contentsline {subsection}{\numberline {8.3}{DQN（Deep Q-Network）}}{36}{subsection.8.3}%
\contentsline {paragraph}{{主要技术}}{36}{paragraph*.69}%
\contentsline {paragraph}{{double-DQN}}{37}{paragraph*.70}%
\contentsline {section}{\numberline {9}{策略梯度（policy gradient）}}{38}{section.9}%
\contentsline {subsection}{\numberline {9.1}{概念}}{38}{subsection.9.1}%
\contentsline {paragraph}{{目标}}{38}{paragraph*.71}%
\contentsline {paragraph}{{似然率策略梯度}}{38}{paragraph*.72}%
\contentsline {paragraph}{{优势}}{39}{paragraph*.73}%
\contentsline {subsection}{\numberline {9.2}{REINFORCE（MC-policy gradient）}}{39}{subsection.9.2}%
\contentsline {paragraph}{{减小方差的方法}}{39}{paragraph*.74}%
\contentsline {section}{\numberline {10}{Actor-Critic方法}}{41}{section.10}%
\contentsline {section}{\numberline {11}{策略搜索方法总结对比}}{41}{section.11}%
\contentsline {section}{\numberline {12}{附录}}{41}{section.12}%
\contentsline {subsection}{\numberline {12.1}{历史}}{41}{subsection.12.1}%
\contentsline {subsection}{\numberline {12.2}{贝尔曼最优方程求解}}{41}{subsection.12.2}%
\contentsline {paragraph}{{收缩映射定理}}{41}{paragraph*.75}%
\contentsline {paragraph}{{贝尔曼最优方程的伸缩映射性}}{42}{paragraph*.76}%
\contentsline {paragraph}{{贝尔曼最优方程解的性质}}{42}{paragraph*.77}%
\contentsline {subsection}{\numberline {12.3}{表格型方法}}{43}{subsection.12.3}%
\contentsline {subsubsection}{\numberline {12.3.1}{模型和规划}}{43}{subsubsection.12.3.1}%
\contentsline {paragraph}{{模型}}{43}{paragraph*.78}%
\contentsline {paragraph}{{规划}}{43}{paragraph*.79}%
\contentsline {paragraph}{{统一的状态空间规划算法}}{43}{paragraph*.80}%
\contentsline {subsubsection}{\numberline {12.3.2}{Dyna-Q}}{43}{subsubsection.12.3.2}%
\contentsline {paragraph}{{框架}}{44}{paragraph*.81}%
\contentsline {subsubsection}{\numberline {12.3.3}{改进方法}}{44}{subsubsection.12.3.3}%
\contentsline {paragraph}{{模型错误}}{44}{paragraph*.82}%
\contentsline {paragraph}{{优先遍历}}{44}{paragraph*.83}%
\contentsline {paragraph}{{轨迹采样}}{45}{paragraph*.84}%
\contentsline {paragraph}{{启发式搜索}}{45}{paragraph*.85}%
\contentsline {paragraph}{{预演算法}}{45}{paragraph*.86}%
\contentsline {subsection}{\numberline {12.4}{核函数近似}}{46}{subsection.12.4}%
\contentsline {paragraph}{{与线性参数化的关系}}{46}{paragraph*.87}%
\contentsline {paragraph}{{优势}}{46}{paragraph*.88}%
\contentsline {subsection}{\numberline {12.5}{数学基础}}{46}{subsection.12.5}%
\contentsline {paragraph}{{概率空间$ (\Omega , F, P) $}}{46}{paragraph*.89}%
\contentsline {paragraph}{{随机变量}}{47}{paragraph*.90}%
\contentsline {paragraph}{{条件概率与独立性}}{47}{paragraph*.91}%
\contentsline {paragraph}{{马尔可夫链与转移概率}}{47}{paragraph*.92}%
\contentsline {paragraph}{{大数定律与中心极限定理}}{47}{paragraph*.93}%
\contentsline {paragraph}{{泛函分析}}{48}{paragraph*.94}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
